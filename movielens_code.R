################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)


#Returns the average ratings for the given training set.
get_aver_ratings <- function(train_set) {
  mean(train_set$rating)
}

#Calculates the bias associated with the movies, one of the constituent elements of the final predicting model.
get_bias_movies <- function(train_set, aver_r, lambda) {
  train_set %>% group_by(movieId) %>% 
				        summarize(bias_m = sum(rating - aver_r) / (n() + lambda))
}

#Calculates the bias associated with the users, one of the constituent elements of the final predicting model.
get_bias_users <- function(train_set, aver_r, bias_m, lambda) {
  train_set %>% left_join(bias_m, by="movieId") %>% 
				        group_by(userId) %>% 
				        summarize(bias_u = sum(rating - bias_m - aver_r) / (n() + lambda)) 
}

#It returns the predictions on the test set by applying the given lambda and the training set information. 
get_prediction <- function(train_set, test_set, lambda, cleaning = TRUE, only_pred = TRUE) {
  
  #Getting the essential parts of the predictive model by using the training set.
  aver_r <- get_aver_ratings(train_set)
  bias_m <- get_bias_movies(train_set, aver_r, lambda)
  bias_u <- get_bias_users(train_set, aver_r, bias_m, lambda)
  
  #Applying the values generated by using the training set to make the predictions on the test set. 
  output <- test_set %>% 
			      left_join(bias_m, by = "movieId") %>% 
			      left_join(bias_u, by = "userId") %>% 
			      mutate(pred = aver_r + bias_m + bias_u)
  
  if (cleaning) {
    #Replacing invalid values caused by wrong input data and calculations. 
    min_r <- min(train_set$rating)
    max_r <- max(train_set$rating)
    output <- output %>% mutate(
              pred = ifelse(is.na(pred), aver_r, #NA to average.
              ifelse(pred < min_r, min_r, #Below minimum to minimum. 
              ifelse(pred > max_r, max_r, #Above maximum to maximum. 
              pred))))
  }
  
  if (only_pred) {
    #Returning only the predictions.
    output$pred 
  }
  else { 
    #Returning all the variables (inputs, predictions and intermediate calculations).
    output 
  }
}

#Finds out what is the best value of lambda for the given data set.
get_lambda <- function(train_set) {
  
  #Dividing the training data set into training/test subsets to emulate more realistic conditions.
  test_subindex <- createDataPartition(train_set$movieId, times = 1, p = 0.5, list = FALSE)
  train_subset <- train_set %>% slice(-test_subindex)
  test_subset <- train_set %>% slice(test_subindex)
  
  #In order to know what is the best lambda value under the current conditions, the input information
  #is used to get predictions by trying a reasonably big number of potential lambda values.
  lambdas <- seq(0, 7, 0.5) 
  rmses <- sapply(lambdas, function(lambda) { 
                  pred <- get_prediction(train_subset, test_subset, lambda)
			            return(RMSE(pred, test_subset$rating))})
  
  #The lambda value delivering the lowest RMSE is assumed to be the best one.
  lambdas[which.min(rmses)] 
}

#Returns the RMSE associated with the input values.
get_rmse <- function(pred, real) { 
  sqrt(mean((pred - real)^2)) 
}

#Defining the training and test sets.
train_set <- edx 
test_set <- validation

#Getting the best lambda for the current training set.
lambda <- get_lambda(train_set)

#Making predictions on the test set by using the training set and the best lambda value.
pred <- get_prediction(train_set, test_set, lambda)

#Calculating and printing out the RMSE value associated with the generated predictions.
rmse <- get_rmse(pred, test_set$rating)
rmse